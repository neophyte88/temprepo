{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pract7dsbda.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMG2pIHSQkLOsyvtbeDiwS9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DtN4PlymW-v5"},"outputs":[],"source":["!pip install nltk"]},{"cell_type":"code","source":["pip install --upgrade pip"],"metadata":{"id":"ZlHBj4tLXBVS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Loading NLTK\n","import nltk\n","nltk.download('punkt')"],"metadata":{"id":"Df6e8pKWXCl7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize\n","text=\"\"\"Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome. The sky is pinkish-blue. You shouldn't eat cardboard\"\"\"\n","tokenized_text = sent_tokenize(text)\n","print(tokenized_text)"],"metadata":{"id":"3xIpTO_lXEMs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","tokenized_word=word_tokenize(text)\n","print(tokenized_word)"],"metadata":{"id":"biOofspRXF5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.probability import FreqDist\n","fdist = FreqDist(tokenized_word)\n","print(fdist)\n","\n","fdist.most_common(2)"],"metadata":{"id":"kGOl2HcrXHcu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Frequency Distribution Plot\n","import matplotlib.pyplot as plt\n","fdist.plot(30,cumulative=False)\n","plt.show()"],"metadata":{"id":"icfmZ8EcXNEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","stop_words=set(stopwords.words(\"english\"))\n","print(stop_words)"],"metadata":{"id":"Z2XkCa6DXOX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filtered_sent=[]\n","for w in tokenized_word:\n","    if w not in stop_words:\n","        filtered_sent.append(w)\n","print(\"Tokenized Sentence:\",tokenized_word)\n","print(\"Filterd Sentence:\",filtered_sent)"],"metadata":{"id":"IYWnqwbBXPph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Stemming\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","ps = PorterStemmer()\n","\n","stemmed_words=[]\n","for w in filtered_sent:\n","    stemmed_words.append(ps.stem(w))\n","\n","print(\"Filtered Sentence:\",filtered_sent)\n","print(\"Stemmed Sentence:\",stemmed_words)"],"metadata":{"id":"UL3u2lS_XRn7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Lexicon Normalization\n","#performing stemming and Lemmatization\n","\n","from nltk.stem.wordnet import WordNetLemmatizer\n","import nltk \n","nltk.download('wordnet')\n","lem = WordNetLemmatizer()\n","\n","from nltk.stem.porter import PorterStemmer\n","stem = PorterStemmer()\n","\n","word = \"connecting\"\n","print(\"Lemmatized Word:\",lem.lemmatize(word,\"v\"))\n","print(\"Stemmed Word:\",stem.stem(word))"],"metadata":{"id":"_BLw4pYBXTSz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sent = \"Albert Einstein was born in Ulm, Germany in 1879.\"\n","\n","tokens=nltk.word_tokenize(sent)\n","print(tokens)"],"metadata":{"id":"1d9kx0O9XUxL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","nltk.pos_tag(tokens)"],"metadata":{"id":"3XqVtVG2XXbt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import pandas\n","import pandas as pd\n","data=pd.read_csv('/content/train.tsv', sep='\\t')\n","data.head()\n","\n","data.info()"],"metadata":{"id":"1O38VEyzXffz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.value_counts()\n","#data.Sentiment.value_counts()"],"metadata":{"id":"PLqQ_qYvXlUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Sentiment_count=data.groupby('Sentiment').count()\n","plt.bar(Sentiment_count.index.values, Sentiment_count['Phrase'])\n","plt.xlabel('Review Sentiments')\n","plt.ylabel('Number of Review')\n","plt.show()"],"metadata":{"id":"7FcrquIIXmiM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from nltk.tokenize import RegexpTokenizer\n","#tokenizer to remove unwanted elements from out data like symbols and numbers\n","token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n","cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n","text_counts= cv.fit_transform(data['Phrase'])"],"metadata":{"id":"fozRARNkXn1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    text_counts, data['Sentiment'], test_size=0.3, random_state=1)"],"metadata":{"id":"pEFaIlU7XpU2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.naive_bayes import MultinomialNB\n","#Import scikit-learn metrics module for accuracy calculation\n","from sklearn import metrics\n","# Model Generation Using Multinomial Naive Bayes\n","clf = MultinomialNB().fit(X_train, y_train)\n","predicted= clf.predict(X_test)\n","print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"],"metadata":{"id":"sCx239wXXq32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","tf=TfidfVectorizer()\n","text_tf= tf.fit_transform(data['Phrase'])\n","\n","print(text_tf)"],"metadata":{"id":"Jjh0Le3rXscv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    text_tf, data['Sentiment'], test_size=0.3, random_state=123)"],"metadata":{"id":"XIj8N3QhXveh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.naive_bayes import MultinomialNB\n","from sklearn import metrics\n","# Model Generation Using Multinomial Naive Bayes\n","clf = MultinomialNB().fit(X_train, y_train)\n","predicted= clf.predict(X_test)\n","print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"],"metadata":{"id":"K-oFkS6-Xwwh"},"execution_count":null,"outputs":[]}]}